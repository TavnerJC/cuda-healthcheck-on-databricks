# Databricks Deployment Guide

This guide explains how to deploy and run the CUDA Healthcheck Tool on Databricks GPU clusters.

**Supports:**
- ‚úÖ **Classic ML Runtime** clusters (driver + workers)
- ‚úÖ **Serverless GPU Compute** (single-user, no SparkContext)

**üìñ Additional Resources:**
- üöÄ [Visual Quick Start Guide](DATABRICKS_QUICK_START.md) - Step-by-step with emoji indicators
- üìä [Installation Flow Diagrams](INSTALLATION_FLOW_DIAGRAM.md) - ASCII diagrams showing correct process
- ‚ùå [Common Mistakes](INSTALLATION_FLOW_DIAGRAM.md#-common-mistakes) - What NOT to do

---

## üéØ Quick Start

### Choose Your Runtime:

**Classic ML Runtime** ‚Üí Use `databricks_healthcheck.py`  
**Serverless GPU Compute** ‚Üí Use `databricks_healthcheck_serverless.py`

Not sure? The tool **auto-detects** and uses the right method!

### 1. Import the Notebook

**Option A: Direct URL Import**
1. In Databricks, go to **Workspace** ‚Üí **Import**
2. Select **URL**
3. Paste: `https://raw.githubusercontent.com/TavnerJC/cuda-healthcheck-on-databricks/main/notebooks/databricks_healthcheck.py`
4. Click **Import**

**Option B: Clone the Repository**
1. In Databricks, go to **Repos** ‚Üí **Add Repo**
2. Git URL: `https://github.com/TavnerJC/cuda-healthcheck-on-databricks`
3. Navigate to `notebooks/databricks_healthcheck.py`

### 2. Create a GPU Cluster

**Minimum Requirements:**
- **Runtime:** Databricks Runtime 13.3 LTS ML or higher
- **Instance Type:** GPU-enabled (g5.xlarge, g5.4xlarge, p3.2xlarge, etc.)
- **Python:** 3.10+

**Example Cluster Configuration:**
```
Cluster Mode: Standard
Databricks Runtime: 13.3 LTS ML (includes Apache Spark 3.4.1, GPU, Scala 2.12)
Worker Type: g5.4xlarge (1 GPU, 16 vCPUs, 64 GB RAM)
Workers: 1-4 (autoscaling)
Driver Type: i3.xlarge (no GPU needed)
```

### 3. Run the Notebook

1. Attach the notebook to your GPU cluster (or serverless compute)
2. **Run Cell 1** (`%pip install git+https://...`)
   - ‚ö†Ô∏è **You'll see a red note:** "Note: you may need to restart the kernel using %restart_python or dbutils.library.restartPython()"
   - ‚úÖ **This is NORMAL and EXPECTED!** It means the package installed successfully.
3. **Run Cell 2** (`dbutils.library.restartPython()`)
   - ‚è∏Ô∏è The notebook will pause for ~10 seconds while Python restarts
   - ‚úÖ After restart, all variables are cleared (expected behavior)
   - ‚ö†Ô∏è **Do NOT re-run Cell 1** after the restart
4. **Run Cell 3+** to perform GPU detection and analysis
5. Review the output

> **üí° Tip:** The restart is necessary because Python needs to reload its module cache to recognize the newly installed package. Without the restart, you'll get `ModuleNotFoundError: No module named 'cuda_healthcheck'`.

---

## üìä Classic vs Serverless: Key Differences

### Classic ML Runtime Clusters

**Architecture:**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Driver Node    ‚îÇ  ‚Üê Notebooks run here
‚îÇ  (CPU only)     ‚îÇ  ‚Üê Package installed here
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ         ‚îÇ         ‚îÇ         ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇWorker 1‚îÇ ‚îÇWorker 2‚îÇ ‚îÇWorker 3‚îÇ ‚îÇWorker 4‚îÇ ‚Üê GPUs here!
‚îÇ(GPU)   ‚îÇ ‚îÇ(GPU)   ‚îÇ ‚îÇ(GPU)   ‚îÇ ‚îÇ(GPU)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Characteristics:**
- ‚úÖ Multiple worker nodes with GPUs
- ‚úÖ Distributed Spark execution
- ‚úÖ `sparkContext` access available
- ‚úÖ Scales to many GPUs
- ‚ö†Ô∏è Requires Spark-based GPU detection

**Use Case:** Large-scale distributed ML training

---

### Serverless GPU Compute

**Architecture:**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Single Process     ‚îÇ  ‚Üê Everything runs here
‚îÇ  (with GPU)         ‚îÇ  ‚Üê Direct GPU access
‚îÇ  No SparkContext    ‚îÇ  ‚Üê Simplified model
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Characteristics:**
- ‚úÖ Single-user execution
- ‚úÖ GPU directly accessible
- ‚úÖ Faster startup
- ‚úÖ Simpler architecture
- ‚ùå No `sparkContext` access
- ‚ö†Ô∏è Limited to single GPU per process

**Limitations:**
- Cannot access `sc = spark.sparkContext`
- Cannot use RDD operations
- No distributed execution patterns

**Use Case:** Single-user notebooks, rapid prototyping

**Learn More:** [Databricks Serverless Limitations](https://docs.databricks.com/release-notes/serverless.html#limitations)

---

## ü§ñ Auto-Detection (Recommended)

The tool **automatically detects** your environment and uses the correct method:

```python
from cuda_healthcheck.databricks import detect_gpu_auto, is_serverless_environment

# Check environment
if is_serverless_environment():
    print("üìç Running on Serverless GPU Compute")
else:
    print("üìç Running on Classic ML Runtime")

# Auto-detect GPUs (works everywhere!)
gpu_info = detect_gpu_auto()

if gpu_info['success']:
    print(f"‚úÖ Found {gpu_info.get('gpu_count', 0)} GPU(s)")
    print(f"   Method: {gpu_info['method']}")  # 'direct' or 'distributed'
    print(f"   Environment: {gpu_info['environment']}")  # 'serverless' or 'classic'
```

---

## üìä What Gets Detected

### Cell 3: GPU Detection
- Physical GPU count and models
- CUDA driver version
- GPU memory
- Compute capability
- Number of Spark executors

### Cell 4: Breaking Changes
- PyTorch compatibility issues
- TensorFlow compatibility issues
- RAPIDS/cuDF compatibility issues
- CUDA version transition risks
- Compatibility scores (0-100)

---

## üèóÔ∏è Architecture

### Driver vs Worker Nodes

Databricks clusters have a **driver-worker architecture**:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Driver Node    ‚îÇ  ‚Üê Notebooks run here (usually no GPU)
‚îÇ  (i3.xlarge)    ‚îÇ  ‚Üê Package installed here via %pip
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ         ‚îÇ         ‚îÇ         ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇWorker 1‚îÇ ‚îÇWorker 2‚îÇ ‚îÇWorker 3‚îÇ ‚îÇWorker 4‚îÇ ‚Üê GPUs are here!
‚îÇ(g5.4xl)‚îÇ ‚îÇ(g5.4xl)‚îÇ ‚îÇ(g5.4xl)‚îÇ ‚îÇ(g5.4xl)‚îÇ ‚Üê 16 executors per worker
‚îÇ1x A10G ‚îÇ ‚îÇ1x A10G ‚îÇ ‚îÇ1x A10G ‚îÇ ‚îÇ1x A10G ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Key Points:**
- `%pip install` only installs on the **driver**
- GPUs are on the **workers**
- We use Spark to run detection on workers
- Results are collected back to the driver

---

## üîß Advanced: Full Distributed Healthcheck

For complete healthcheck functionality on workers (not just GPU detection), install the package **cluster-wide**:

### Method 1: Cluster Libraries (Recommended)

1. Go to your cluster configuration
2. Click **Libraries** tab
3. Click **Install New** ‚Üí **PyPI**
4. Enter: `git+https://github.com/TavnerJC/cuda-healthcheck-on-databricks.git`
5. Click **Install**
6. **Restart the cluster**

Now you can run the full `DatabricksHealthchecker` on workers!

### Method 2: Init Script

Create an init script to install on cluster startup:

```bash
#!/bin/bash
pip install git+https://github.com/TavnerJC/cuda-healthcheck-on-databricks.git
```

Upload to DBFS and configure in cluster settings.

---

## üìù Example Output

### Successful Detection

```
================================================================================
üñ•Ô∏è  DRIVER NODE
================================================================================
Driver: No GPU detected (expected for driver node)

================================================================================
üéÆ WORKER NODES - GPU DETECTION
================================================================================
üìä Cluster Configuration:
   Spark Executors: 16
   Unique Worker Nodes: 1

üìç Worker Node 1: ip-10-0-1-234.ec2.internal
   Physical GPUs: 1
      GPU 0: NVIDIA A10G
         Driver: 535.161.07
         Memory: 23028 MiB
         Compute Capability: 8.6

================================================================================
‚úÖ ACTUAL PHYSICAL GPUs in cluster: 1
   (Detected 16 times - once per Spark executor)
================================================================================
```

### Compatibility Analysis

```
================================================================================
üîç CUDA BREAKING CHANGES ANALYSIS
================================================================================

üì¶ PyTorch Breaking Changes:
   ‚úÖ Found 2 PyTorch breaking changes

üì¶ TensorFlow Breaking Changes:
   ‚úÖ Found 2 TensorFlow breaking changes

üîÑ CUDA Version Transition Analysis:
   CUDA 11.8 ‚Üí 12.0: 2 breaking changes
   CUDA 12.0 ‚Üí 13.0: 6 breaking changes

================================================================================
üíØ COMPATIBILITY SCORING
================================================================================

üìä CUDA 12.0 Compatibility:
   Score: 100/100
   Critical: 0 | Warnings: 0
   Status: GOOD: Environment is highly compatible.

üìä CUDA 13.0 Compatibility:
   Score: 40/100
   Critical: 2 | Warnings: 0
   Status: CRITICAL: Breaking changes detected. Test before upgrading!

================================================================================
```

---

## ‚ö†Ô∏è Common Issues

### Issue 1: "ModuleNotFoundError: No module named 'cuda_healthcheck'"

**Cause:** You tried to import the package before installing it, or you didn't restart Python after installation.

**Solution:**
```python
# Cell 1: Install
%pip install git+https://github.com/TavnerJC/cuda-healthcheck-on-databricks.git

# Cell 2: Restart (REQUIRED!)
dbutils.library.restartPython()

# Cell 3: Now import works
from cuda_healthcheck import CUDADetector
```

### Issue 2: Red warning note after %pip install

**Message you'll see:**  
> "Note: you may need to restart the kernel using %restart_python or dbutils.library.restartPython()"

**Status:** ‚úÖ **This is COMPLETELY NORMAL!** It means the package installed successfully.

**What to do:**  
1. ‚úÖ Celebrate - installation worked!
2. ‚úÖ Run `dbutils.library.restartPython()` in the next cell
3. ‚ö†Ô∏è Do NOT re-run the install cell after restarting
4. ‚úÖ Continue with imports in Cell 3+

**Why this happens:** Python needs to restart to recognize the newly installed package. Without the restart, you'll get `ModuleNotFoundError`.

### Issue 3: "No GPU detected on driver"

**Expected!** The driver node typically doesn't have a GPU. GPUs are on worker nodes.

### Issue 4: "Package import fails on workers"

**Solution:** Install package cluster-wide (see Advanced section above).

### Issue 5: "16 GPUs detected but only 1 physical GPU"

**Expected!** Each Spark executor reports the GPU. The code deduplicates by UUID to show actual physical GPUs.

### Issue 6: "Cell hangs with py4j messages"

**Cause:** Trying to import package on workers when it's only installed on driver.  
**Solution:** Use the provided notebook which avoids package imports on workers for basic detection.

### Issue 7: "Variables undefined after restart"

**Status:** ‚úÖ **This is EXPECTED Python behavior!**

When you run `dbutils.library.restartPython()`, all variables are cleared. This is how Python restarts work.

**What to do:** Don't try to use variables from Cell 1 in Cell 3+. The restart clears everything.

### Issue 8: Serverless: "[JVM_ATTRIBUTE_NOT_SUPPORTED] ... 'sparkContext'"

**Cause:** Trying to use Spark/SparkContext on Serverless GPU Compute (not supported).

**Solution:** Use `databricks_healthcheck_serverless.py` notebook which uses `detect_gpu_auto()` for serverless-compatible detection.

---

## üéØ Use Cases

### 1. Pre-Deployment Validation
Run before deploying ML models to verify CUDA compatibility.

### 2. Cluster Configuration Audit
Validate that your cluster has the expected GPU configuration.

### 3. Framework Upgrade Planning
Check compatibility scores before upgrading PyTorch, TensorFlow, or CUDA.

### 4. Breaking Changes Detection
Identify critical issues before they cause production failures.

### 5. Multi-Cluster Comparison
Run on different clusters to compare configurations.

---

## üìö Additional Resources

- [Main README](../README.md) - Full documentation
- [API Reference](../docs/API_REFERENCE.md) - Detailed API docs
- [Local Testing](../TESTING_AND_NOTEBOOKS_SUMMARY.md) - Run tests locally
- [CI/CD](../docs/CICD.md) - GitHub Actions workflows

---

## üí° Tips

1. **Run regularly:** Add to your cluster startup routine
2. **Before upgrades:** Always check compatibility scores
3. **Save results:** Export to Delta table for historical tracking
4. **Team sharing:** Share the notebook with your ML team
5. **Custom checks:** Extend the notebook for your specific needs

---

## üÜò Support

- **GitHub Issues:** [Report bugs or request features](https://github.com/TavnerJC/cuda-healthcheck-on-databricks/issues)
- **Documentation:** Check the [main README](../README.md)
- **Examples:** See the [notebooks folder](../notebooks/)

---

**Happy GPU Healthchecking!** üéâ


